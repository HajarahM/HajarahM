{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEoIi2Wf0U/Myehk0QzKOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HajarahM/HajarahM/blob/main/Data_Processing_Auto_Clean_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoClean automates data preprocessing & cleaning"
      ],
      "metadata": {
        "id": "MgQDcRhbkq2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjtgAq-9zNq3"
      },
      "outputs": [],
      "source": [
        "pip install py-AutoClean"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Dataset through the default AutoClean pipeline"
      ],
      "metadata": {
        "id": "x0BzP_AvkpWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from AutoClean import AutoClean\n",
        "pipeline = AutoClean(dataset)"
      ],
      "metadata": {
        "id": "25ZkzZ_nkgSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To include adjustable parameters. Set to 'False' if you want autoclean to skip the step. Set to 'auto' if you want autoclean to automate or set to 'manual' if you want to manually do the data cleaning for the specific step or to be specific about the type of 'cleaning' to do in the respective step.\n",
        "\n",
        "For example: For missing_num - You can specify the handling method by setting missing_num to: 'linreg', 'knn', 'mean', 'median', 'most_frequent', 'delete' or to False if you want to skip this step.\n",
        "\n"
      ],
      "metadata": {
        "id": "0x_FXnOElQCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AutoClean(dataset, mode='auto', duplicates='auto', missing_num='False', missing_categ=False,\n",
        "          encode_categ=False, extract_datetime=False, outliers=False, outlier_param=1.5,\n",
        "          logfile=True, verbose=False)"
      ],
      "metadata": {
        "id": "n1QfOj8LlS1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.output\n"
      ],
      "metadata": {
        "id": "x7xsj2rElDgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More ways to add a manual touch\n",
        "\n",
        "**Duplicates**\n",
        "Defines whether AutoClean should handle duplicate values in the data. If set to 'auto' or True, AutoClean will delete the rows it found which are exacte duplicates on all features. Set duplicates to False if you want to skip this step.\n",
        "\n",
        "\n",
        "**missing_num**\n",
        "Defines how numerical missing values in the data are handled. Missing values can be predicted, imputed or deleted. When set to auto, AutoClean first attempts to predict the missing values with Linear Regression, and the values that could not be predicted are imputed with K-NN.\n",
        "\n",
        "You can specify the handling method by setting missing_num to: 'linreg', 'knn', 'mean', 'median', 'most_frequent', 'delete' or to False if you want to skip this step.\n",
        "\n",
        "\n",
        "**missing_categ**\n",
        "Defines how categorical missing values in the data are handled. Missing values can be predicted, imputed or deleted. When set to auto, AutoClean first attempts to predict the missing values with Logistic Regression, and the values that could not be predicted are imputed with K-NN.\n",
        "\n",
        "You can specify the handling method by setting missing_categ to: 'logreg', 'knn', 'most_frequent', 'delete' or to False if you want to skip this step.\n",
        "\n",
        "\n",
        "**encode_categ**\n",
        "Defines how categorical values should be encoded. Categorical values can be onehot- or label-encoded.\n",
        "\n",
        "The parameter must be handed as Python list type. When set to 'auto', AutoClean:\n",
        "\n",
        "onehot-encodes features that have less than 10 unique data values\n",
        "label-encodes features that have less than 20 unique data values\n",
        "does not encode feature having more than 20 unqiue data values\n",
        "You can specify the encoding method manually by setting encode_categ to ['onehot'] or ['label']. By default, AutoClean will encode all categorical features. You can specify which features to encode by giving the column names or indexes as parameter, for example ['onehot', ['column_1', 2]] - this will onehot-encode the column with column name 'column_1' and the column with index '2'.\n",
        "\n",
        "Set encode_categ to False to skip categorical encoding.\n",
        "\n",
        "\n",
        "**extract_datetime**\n",
        "AutoClean can search the data for datetime features, and extract the values to separate columns. When set to 's', it extracts the datetime values up to the seconds i. e. day, month, year, hour, minutes, seconds.\n",
        "\n",
        "You can set the granularity of the extraction manually by setting extract_datetime to 'D' for day, 'M' for month, 'Y' for year, 'h' for hour, 'm' for minutes or to False if you want to skip this step.\n",
        "\n",
        "\n",
        "**outliers**\n",
        "Defines how outliers in the data are handled. Outliers can be manipulated with two different methods: winsorization or deletion. You can specfiy the method by setting 'outliers' to 'winz' for winzorization, 'delete' for deletion or to False if you want to skip this step.\n",
        "\n",
        "When are outliers considered to be outliers?\n",
        "Oberservations are considered outliers if they are outside the following bounds:\n",
        "\n",
        "[Q1 - 1.5*IQR , Q3 + 1.5*IQR]\n",
        "where\n",
        "... Q1 and Q3 are the first and third quartile of the feature values\n",
        "... IQR is the interquartile range of the feature values\n",
        "\n",
        "As soon as a value is below the lower or upper bound, the chosen outlier handling method is applied i. e. either winsorization, meaning it will be replaced by the respective lower or upper bound, or the observation will be deleted.\n",
        "\n",
        "You can customize the outlier bounds by changing the default outlier_param value of 1.5 to any integer or float of your choice. It is not recommended to change the outlier_param value!\n",
        "\n",
        "outlier_param\n",
        "! Recommended not to change default value\n",
        "\n",
        "You can customize the outlier bounds by changing the default outlier_param value of 1.5 to any integer or float of your choice. It is not recommended to change the outlier_param value!\n",
        "\n",
        "\n",
        "**logfile**\n",
        "Defines whether a logfile should be generated while the AutoClean process runs. If set to True, it will create a autoclean.log file in your current working directory.\n",
        "\n",
        "You can view a sample logfile here.\n",
        "\n",
        "\n",
        "**verbose**\n",
        "Defines whether the logfile output should be shown on the console while the AutoClean process runs. Set to True if you want to follow the process logs in real-time."
      ],
      "metadata": {
        "id": "EeKWV5JHnBmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write cleaned data to CSV file"
      ],
      "metadata": {
        "id": "AV4mTdIJyPCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('output.csv', index=False)"
      ],
      "metadata": {
        "id": "iTyksFnZxnt6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}